{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes lint errors from VS Code\n",
    "from typing import Dict, TYPE_CHECKING, Tuple, List\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    import kedro\n",
    "\n",
    "    catalog: kedro.io.data_catalog.DataCatalog\n",
    "    session: kedro.framework.session.session.KedroSession\n",
    "    pipelines: Dict[str, kedro.pipeline.pipeline.Pipeline]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "VIEW = os.getenv(\"DATASET_VIEW\") or \"tab_adult\"\n",
    "TABLE = os.getenv(\"DATASET_TABLE\") or \"table\"\n",
    "MULTI_PROCESS = (\n",
    "    os.getenv(\"MULTI_PROCESS\") if os.getenv(\"MULTI_PROCESS\") is not None else True\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "\n",
    "from pasteur.transform import TableTransformer\n",
    "\n",
    "bhr: pd.DataFrame = catalog.load(f\"{VIEW}.wrk.bhr_{TABLE}\")\n",
    "trn: TableTransformer = catalog.load(f\"{VIEW}.wrk.trn_{TABLE}\")\n",
    "random_state = catalog.load(\"params:random_state\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_0</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt_0</th>\n",
       "      <th>fnlwgt_1</th>\n",
       "      <th>fnlwgt_2</th>\n",
       "      <th>...</th>\n",
       "      <th>capital-loss_3</th>\n",
       "      <th>capital-loss_4</th>\n",
       "      <th>capital-loss_5</th>\n",
       "      <th>hours-per-week_0</th>\n",
       "      <th>hours-per-week_1</th>\n",
       "      <th>hours-per-week_2</th>\n",
       "      <th>hours-per-week_3</th>\n",
       "      <th>hours-per-week_4</th>\n",
       "      <th>hours-per-week_5</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bhr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m12\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m10\u001b[0m, \u001b[1;36m9\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m7\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m19\u001b[0m, \u001b[1;36m18\u001b[0m, \u001b[1;36m17\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m14\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m30\u001b[0m, \u001b[1;36m29\u001b[0m, \u001b[1;36m28\u001b[0m, \u001b[1;36m27\u001b[0m, \u001b[1;36m26\u001b[0m, \u001b[1;36m25\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m36\u001b[0m, \u001b[1;36m35\u001b[0m, \u001b[1;36m34\u001b[0m, \u001b[1;36m33\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m31\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m41\u001b[0m, \u001b[1;36m40\u001b[0m, \u001b[1;36m39\u001b[0m, \u001b[1;36m38\u001b[0m, \u001b[1;36m37\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m43\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[1m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attr_str = trn.get_attributes(\"bhr\", bhr)\n",
    "cols = list(bhr.columns)\n",
    "\n",
    "attr = []\n",
    "for a_cols in attr_str.values():\n",
    "    attr.append([cols.index(col) for col in a_cols])\n",
    "\n",
    "attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m13024\u001b[0m, \u001b[1;36m44\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = bhr.to_numpy(dtype=\"int16\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">array</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">int16</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35marray\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m9\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m, \u001b[1;36m16\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,\n",
       "        \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m7\u001b[0m, \u001b[1;36m15\u001b[0m,  \u001b[1;36m6\u001b[0m,  \u001b[1;36m5\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m1\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,\n",
       "        \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m2\u001b[0m, \u001b[1;36m42\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mint16\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain = data.max(axis=0) + 1\n",
    "domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def calc_mutual_info(data: torch.Tensor, domain: np.ndarray, x: list[int], p: list[int]):\n",
    "#     sub_data = data[:, x + p]\n",
    "#     sub_domain = domain[x + p].tolist()\n",
    "#     margin = torch.histogramdd(sub_data, sub_domain)\n",
    "#     margin /= margin.sum()\n",
    "#     margin += 1e-6\n",
    "#     margin /= margin.sum()\n",
    "\n",
    "#     x_idx = tuple(range(len(x)))\n",
    "#     p_idx = tuple(range(-len(p), 0))\n",
    "\n",
    "#     x_mar = np.sum(margin, axis=p_idx).reshape(-1)\n",
    "#     p_mar = np.sum(margin, axis=x_idx).reshape(-1)\n",
    "#     j_mar = margin.reshape((len(x_mar), len(p_mar)))\n",
    "\n",
    "#     # margin.reshape((len(x_mar), len(p_mar)))\n",
    "#     # margin.shape|\n",
    "#     return np.sum(j_mar*np.log2(j_mar/np.outer(x_mar, p_mar)))\n",
    "\n",
    "# x = [11, 12, 15]\n",
    "# p = [22, 23, 24]\n",
    "# # %lprun -f calc_mutual_info calc_mutual_info(torch.from_numpy(data), torch.from_numpy(domain), x, p)\n",
    "# calc_mutual_info(torch.from_numpy(data), domain, x, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000-01-01 00:00:00,000715: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2000-01-01 00:00:00,000608: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2000-01-01 00:00:00,000301: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/04/22 18:08:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Unable to initialize backend <span style=\"color: #008000; text-decoration-color: #008000\">'tpu_driver'</span>: NOT_FOUND: Unable to find <a href=\"file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xla_bridge.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py#328\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         driver in registry given worker:                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/04/22 18:08:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Unable to initialize backend \u001b[32m'tpu_driver'\u001b[0m: NOT_FOUND: Unable to find \u001b]8;id=571028;file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py\u001b\\\u001b[2mxla_bridge.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=327274;file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py#328\u001b\\\u001b[2m328\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         driver in registry given worker:                                     \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/04/22 18:08:44] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Unable to initialize backend <span style=\"color: #008000; text-decoration-color: #008000\">'rocm'</span>: NOT_FOUND: Could not find       <a href=\"file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xla_bridge.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py#328\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         registered platform with name: <span style=\"color: #008000; text-decoration-color: #008000\">\"rocm\"</span>. Available platform names are: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         CUDA Interpreter Host                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/04/22 18:08:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Unable to initialize backend \u001b[32m'rocm'\u001b[0m: NOT_FOUND: Could not find       \u001b]8;id=814139;file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py\u001b\\\u001b[2mxla_bridge.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=337728;file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py#328\u001b\\\u001b[2m328\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         registered platform with name: \u001b[32m\"rocm\"\u001b[0m. Available platform names are: \u001b[2m                 \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         CUDA Interpreter Host                                                \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Unable to initialize backend <span style=\"color: #008000; text-decoration-color: #008000\">'tpu'</span>: module <span style=\"color: #008000; text-decoration-color: #008000\">'jaxlib.xla_extension'</span>    <a href=\"file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">xla_bridge.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py#328\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'get_tpu_client'</span>                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Unable to initialize backend \u001b[32m'tpu'\u001b[0m: module \u001b[32m'jaxlib.xla_extension'\u001b[0m    \u001b]8;id=136575;file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py\u001b\\\u001b[2mxla_bridge.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=255816;file:///mnt/ext/projects/pasteur/venv/lib/python3.10/site-packages/jax/_src/lib/xla_bridge.py#328\u001b\\\u001b[2m328\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         has no attribute \u001b[32m'get_tpu_client'\u001b[0m                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000-01-01 00:00:00,000659: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000161: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000955: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000428: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000376: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000493: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000690: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000325: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000980: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000701: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000716: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000454: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000626: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000179: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000647: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000369: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000417: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000204: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000291: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000905: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000652: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000383: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000478: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000810: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000136: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000598: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000248: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000184: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000553: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000673: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000698: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000011: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000600: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000052: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000089: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000026: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000185: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000931: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000593: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000587: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000582: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000185: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000389: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000978: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000323: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000722: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000582: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000046: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000804: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000043: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000453: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000053: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000500: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000379: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000557: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000573: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000246: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000962: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000547: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000612: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000101: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000076: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000153: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2000-01-01 00:00:00,000607: W external/org_tensorflow/tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.3 ms Â± 1.36 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def calc_mutual_info(data: jnp.ndarray, domain: jnp.ndarray, x: list[int], p: list[int]):\n",
    "    sub_data = data[:, jnp.asarray(x + p)]\n",
    "    sub_domain = domain[jnp.asarray(x + p)]\n",
    "    margin, _ = jnp.histogramdd(sub_data, sub_domain)\n",
    "    margin /= margin.sum()\n",
    "    margin += 1e-6\n",
    "    margin /= margin.sum()\n",
    "\n",
    "    x_idx = tuple(range(len(x)))\n",
    "    p_idx = tuple(range(-len(p), 0))\n",
    "\n",
    "    x_mar = jnp.sum(margin, axis=p_idx).reshape(-1)\n",
    "    p_mar = jnp.sum(margin, axis=x_idx).reshape(-1)\n",
    "    j_mar = margin.reshape((len(x_mar), len(p_mar)))\n",
    "\n",
    "    # margin.reshape((len(x_mar), len(p_mar)))\n",
    "    # margin.shape|\n",
    "    return jnp.sum(j_mar*jnp.log2(j_mar/jnp.outer(x_mar, p_mar)))\n",
    "\n",
    "x = [11, 12, 15]\n",
    "p = [22, 23, 24]\n",
    "# %lprun -f calc_mutual_info calc_mutual_info(data, domain, x, p)\n",
    "jdata = jnp.asarray(data)\n",
    "jdomain = jnp.asarray(domain)\n",
    "%timeit calc_mutual_info(jdata, jdomain, x, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.65 ms Â± 21.1 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def calc_mutual_info(data: np.ndarray, domain: np.ndarray, x: list[int], p: list[int]):\n",
    "    sub_data = data[:, x + p]\n",
    "    sub_domain = domain[x + p]\n",
    "    margin, _ = np.histogramdd(sub_data, sub_domain)\n",
    "    margin /= margin.sum()\n",
    "    margin += 1e-24\n",
    "\n",
    "    x_idx = tuple(range(len(x)))\n",
    "    p_idx = tuple(range(-len(p), 0))\n",
    "\n",
    "    x_mar = np.sum(margin, axis=p_idx).reshape(-1)\n",
    "    p_mar = np.sum(margin, axis=x_idx).reshape(-1)\n",
    "    j_mar = margin.reshape((len(x_mar), len(p_mar)))\n",
    "\n",
    "    # margin.reshape((len(x_mar), len(p_mar)))\n",
    "    # margin.shape|\n",
    "    return np.sum(j_mar*np.log(j_mar/np.outer(x_mar, p_mar)))\n",
    "\n",
    "x = [11, 12, 13, 14]\n",
    "p = [22, 23, 24, 25]\n",
    "# %lprun -f calc_mutual_info calc_mutual_info(data, domain, x, p)\n",
    "dt = data.astype(dtype=\"int16\")\n",
    "%timeit calc_mutual_info(dt, domain, x, p)\n",
    "# calc_mutual_info(data, domain, x, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73 ms Â± 7.82 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "true = data[:, 11] * domain[12] + data[:, 12]\n",
    "pred = data[:, 22] * domain[23] + data[:, 23]\n",
    "\n",
    "# true = data[:, x]\n",
    "mutual_info_score(pred,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "50661068d2d5c6ff1ce24ae701dfa73cc4ae117a223c3f7199e1fdb4656c8912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
