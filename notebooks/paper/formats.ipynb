{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34mINFO    \u001b[0m Kedro project Pasteur                                                                                           \u001b[2m__init__.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m77\u001b[0m\n",
      "\u001b[0m\u001b[34mINFO    \u001b[0m Defined global variable \u001b[32m'context'\u001b[0m, \u001b[32m'session'\u001b[0m, \u001b[32m'catalog'\u001b[0m and \u001b[32m'pipelines'\u001b[0m                                         \u001b[2m__init__.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m78\u001b[0m\n",
      "\u001b[0m\u001b[34mINFO    \u001b[0m Registered line magic \u001b[32m'run_viz'\u001b[0m                                                                                 \u001b[2m__init__.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m84\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pasteur.kedro.ipython import * # type: ignore\n",
    "register_kedro() # type: ignore\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TARGET = 1e9 # scale partition to 1 billion\n",
    "GB_BYTES = 1e9\n",
    "\n",
    "def mem_usage(df: pd.DataFrame):\n",
    "    \"\"\" Calculates the equivalent memory usage when scaled to 1 billion rows. \"\"\"\n",
    "    ngb = sum(df.memory_usage(deep=True)) / GB_BYTES * (TARGET / df.shape[0])\n",
    "    print(f\"Number of rows: {df.shape[0]:,d}\")\n",
    "    print(f'Size for 1B rows: {ngb:,.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15351224 entries, 51118402 to 59901588\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   charttime       datetime64[ns]\n",
      " 1   valuenum        float32       \n",
      " 2   valueuom        category      \n",
      " 3   warning         bool          \n",
      " 4   first_careunit  category      \n",
      " 5   last_careunit   category      \n",
      " 6   intime          datetime64[ns]\n",
      " 7   outtime         datetime64[ns]\n",
      " 8   gender          category      \n",
      " 9   birth_year      datetime64[ns]\n",
      "dtypes: bool(1), category(4), datetime64[ns](4), float32(1)\n",
      "memory usage: 717.4 MB\n"
     ]
    }
   ],
   "source": [
    "optimised = catalog.load('mimic_billion.wrk.table').sample()\n",
    "optimised.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 15,351,224\n",
      "Size for 1B rows: 49.00 GB\n"
     ]
    }
   ],
   "source": [
    "mem_usage(optimised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 15,351,224\n",
      "Size for 1B rows: 776.87 GB\n"
     ]
    }
   ],
   "source": [
    "raw = optimised.astype(\n",
    "    {\n",
    "        # By default, \n",
    "        \"valuenum\": \"float64\",\n",
    "        # By default, string columns become objects. Category is much more efficient.\n",
    "        \"valueuom\": \"object\",\n",
    "        \"first_careunit\": \"object\",\n",
    "        \"last_careunit\": \"object\",\n",
    "        \"gender\": \"object\",\n",
    "        # By default, pandas doesn't parse dates\n",
    "        \"intime\": \"object\",\n",
    "        \"outtime\": \"object\",\n",
    "        \"birth_year\": \"object\",\n",
    "        \"charttime\": \"object\"\n",
    "    }\n",
    ")\n",
    "mem_usage(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15351224 entries, 51118402 to 59901588\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Dtype\n",
      "---  ------          -----\n",
      " 0   intime_year     uint8\n",
      " 1   intime_week     uint8\n",
      " 2   intime_day      uint8\n",
      " 3   intime_time     uint8\n",
      " 4   outtime_week    uint8\n",
      " 5   outtime_day     uint8\n",
      " 6   outtime_time    uint8\n",
      " 7   charttime_week  uint8\n",
      " 8   charttime_day   uint8\n",
      " 9   charttime_time  uint8\n",
      " 10  valuenum        uint8\n",
      " 11  valueuom        uint8\n",
      " 12  warning         uint8\n",
      " 13  first_careunit  uint8\n",
      " 14  last_careunit   uint8\n",
      " 15  gender          uint8\n",
      "dtypes: uint8(16)\n",
      "memory usage: 351.4 MB\n"
     ]
    }
   ],
   "source": [
    "idx = catalog.load('mimic_billion.wrk.idx_table').sample()\n",
    "idx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 15,351,224\n",
      "Size for 1B rows: 24.00 GB\n"
     ]
    }
   ],
   "source": [
    "mem_usage(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 15,351,224\n",
      "Size for 1B rows: 136.00 GB\n"
     ]
    }
   ],
   "source": [
    "idx64 = idx.astype('int64')\n",
    "mem_usage(idx64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig: .csv -> .csv.gz -> .pq\n",
      "CPU times: user 2min 23s, sys: 3.64 s, total: 2min 27s\n",
      "Wall time: 2min 27s\n",
      "CPU times: user 5min 38s, sys: 1.23 s, total: 5min 40s\n",
      "Wall time: 5min 40s\n",
      "CPU times: user 5.98 s, sys: 392 ms, total: 6.37 s\n",
      "Wall time: 7.18 s\n",
      "idx: .csv -> .csv.gz -> .pq\n",
      "CPU times: user 56.2 s, sys: 1.22 s, total: 57.4 s\n",
      "Wall time: 57.4 s\n",
      "CPU times: user 5min 40s, sys: 930 ms, total: 5min 41s\n",
      "Wall time: 5min 46s\n",
      "CPU times: user 5.74 s, sys: 473 ms, total: 6.22 s\n",
      "Wall time: 8.71 s\n",
      "idx64: .csv -> .csv.gz -> .pq\n",
      "CPU times: user 1min 12s, sys: 1.84 s, total: 1min 13s\n",
      "Wall time: 1min 25s\n",
      "CPU times: user 5min 55s, sys: 1.02 s, total: 5min 56s\n",
      "Wall time: 6min 25s\n",
      "CPU times: user 5.16 s, sys: 332 ms, total: 5.49 s\n",
      "Wall time: 6.32 s\n",
      "File sizes\n",
      "total 5.2G\n",
      "drwxrwxr-x 2 username username 4.0K Feb  3 19:19 .\n",
      "drwxrwxr-x 3 username username 4.0K Feb  3 19:19 ..\n",
      "-rw-rw-r-- 1 username username 660M Feb  3 19:06 idx.csv\n",
      "-rw-rw-r-- 1 username username 210M Feb  3 19:11 idx.csv.gz\n",
      "-rw-rw-r-- 1 username username 194M Feb  3 19:11 idx.pq\n",
      "-rw-rw-r-- 1 username username 660M Feb  3 19:13 idx64.csv\n",
      "-rw-rw-r-- 1 username username 210M Feb  3 19:19 idx64.csv.gz\n",
      "-rw-rw-r-- 1 username username 194M Feb  3 19:19 idx64.pq\n",
      "-rw-rw-r-- 1 username username 2.4G Feb  3 18:59 orig.csv\n",
      "-rw-rw-r-- 1 username username 450M Feb  3 19:05 orig.csv.gz\n",
      "-rw-rw-r-- 1 username username 301M Feb  3 19:05 orig.pq\n"
     ]
    }
   ],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "\n",
    "tmp = Path('.sizing')\n",
    "!mkdir -p {tmp}\n",
    "\n",
    "print(\"Orig: .csv -> .csv.gz -> .pq\")\n",
    "%time optimised.to_csv(tmp / \"orig.csv\")\n",
    "%time optimised.to_csv(tmp / \"orig.csv.gz\")\n",
    "%time optimised.to_parquet(tmp / \"orig.pq\")\n",
    "\n",
    "print(\"idx: .csv -> .csv.gz -> .pq\")\n",
    "%time idx.to_csv(tmp / \"idx.csv\")\n",
    "%time idx.to_csv(tmp / \"idx.csv.gz\")\n",
    "%time idx.to_parquet(tmp / \"idx.pq\")\n",
    "\n",
    "print(\"idx64: .csv -> .csv.gz -> .pq\")\n",
    "%time idx64.to_csv(tmp / \"idx64.csv\")\n",
    "%time idx64.to_csv(tmp / \"idx64.csv.gz\")\n",
    "%time idx64.to_parquet(tmp / \"idx64.pq\")\n",
    "\n",
    "print(\"File sizes\")\n",
    "out = !ls -lah {tmp}\n",
    "# Remove my username\n",
    "print(\" \".join([\"username\" if \"@\" in s else s for s in \"\\n\".join(out).split(\" \")]))\n",
    "\n",
    "!rm -r {tmp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplier to 1B: 65.1414\n"
     ]
    }
   ],
   "source": [
    "multiplier = 1e9 / idx.shape[0]\n",
    "print(f\"Multiplier to 1B: {multiplier:,.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULT = multiplier\n",
    "mult = lambda min, sec: f\"{int((MULT*(min*60+sec)) // 60)}:{int((MULT*(min*60+sec)) % 60):.3f}\"\n",
    "# mult(2, 23)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec  7 2022, 01:12:00) [GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d48f3171bf93d5bacc74509c6ff913ccf36520ab35bc9e1b8a60d7039aa36cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
