# Pasteur was based on the project kedro-mlflow. However, after extensive 
# customizations, only the config remains and kedro-mlflow has been removed as
# a dependency.

# Pasteur uses logging and visualization nodes to log to mlflow. It automatically
# manages starting and stopping mlflow runs. Your metrics should log to mlflow 
# directly from their visualization functions.

# SERVER CONFIGURATION -------------------
server:
  mlflow_tracking_uri: ${base_location}/reporting/flow
  credentials: null # must be a valid key in credentials.yml which refers to a dict of sensituve mlflow environment variables (password, tokens...)

tracking:
  disable_tracking:
    pipelines: []

  experiment:
    restore_if_deleted: True # if the experiment`name` was previously deleted experiment, should we restore it?

  params:
    dict_params:
      # flatten: False # if True, parameter which are dictionary will be splitted in multiple parameters when logged in mlflow, one for each key.
      recursive: True # Should the dictionary flattening be applied recursively (i.e for nested dictionaries)? Not use if `flatten_dict_params` is False.
      sep: "." # In case of recursive flattening, what separator should be used between the keys? E.g. {hyperaparam1: {p1:1, p2:2}} will be logged as hyperaparam1.p1 and hyperaparam1.p2 in mlflow.
    long_params_strategy: tag # One of ["fail", "tag", "truncate" ] If a parameter is above mlflow limit (currently 250), what should kedro-mlflow do? -> fail, set as a tag instead of a parameter, or truncate it to its 250 first letters?